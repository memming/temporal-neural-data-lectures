@ARTICLE{Paninski2003,
  title    = "Convergence properties of three spike-triggered analysis
              techniques",
  author   = "Paninski, Liam",
  abstract = "We analyse the convergence properties of three spike-triggered
              data analysis techniques. Our results are obtained in the setting
              of a probabilistic linear-nonlinear (LN) cascade neural encoding
              model; this model has recently become popular in the study of the
              neural coding of natural signals. We start by giving exact
              rate-of-convergence results for the common spike-triggered
              average technique. Next, we analyse a spike-triggered covariance
              method, variants of which have been recently exploited
              successfully by Bialek, Simoncelli and colleagues. Unfortunately,
              the conditions that guarantee that these two estimators will
              converge to the correct parameters are typically not satisfied by
              natural signal data. Therefore, we introduce an estimator for the
              LN model parameters which is designed to converge under general
              conditions to the correct model. We derive the rate of
              convergence of this estimator, provide an algorithm for its
              computation and demonstrate its application to simulated data as
              well as physiological data from the primary motor cortex of awake
              behaving monkeys. We also give lower bounds on the convergence
              rate of any possible LN estimator. Our results should prove
              useful in the study of the neural coding of high-dimensional
              natural signals.",
  journal  = "Network: Computation in Neural Systems",
  volume   =  14,
  pages    = "437--464",
  month    =  aug,
  year     =  2003,
  keywords = "consistency, neuroscience, phi-divergence, spike-train, sta,
              statistical-learning"
}

@INPROCEEDINGS{Park2011c,
  author = {Il Memming Park and Jonathan W. Pillow},
  title = {{Bayes}ian Spike Triggered Covariance Analysis},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year = {2011},
  owner = {memming},
  timestamp = {2011.10.24}
}


@INCOLLECTION{Simoncelli2004,
  title     = "Characterization of Neural Responses with Stochastic Stimuli",
  booktitle = "The Cognitive Neurosciences {III}",
  author    = "Simoncelli, E P and Paninski, Liam and Pillow, Jonathan and
               Schwartz, Odelia",
  editor    = "Gazzaniga, Michael S",
  publisher = "The MIT Press",
  pages     = "327",
  chapter   =  23,
  year      =  2004,
  isbn      = "00262072548"
}

@ARTICLE{De_Ruyter_van_Steveninck1997,
  title   = "Reproducibility and Variability in Neural Spike Trains",
  author  = "de Ruyter van Steveninck, Rob R and Lewen, Geoffrey D and Strong,
             Steven P and Koberle, Roland and Bialek, William",
  journal = "Science",
  volume  =  275,
  pages   = "1805--1808",
  year    =  1997,
  issn    = "0036-8075"
}

@INPROCEEDINGS{Park2013f,
  author = {Il Memming Park and Evan Archer and Nicholas Priebe and Jonathan W. Pillow},
  title = {Spectral methods for neural characterization using generalized quadratic models},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year = {2013},
  owner = {memming}
}

@ARTICLE{Pillow2008,
  title     = "Spatio-temporal correlations and visual signalling in a complete
               neuronal population",
  author    = "Pillow, Jonathan W and Shlens, Jonathon and Paninski, Liam and
               Sher, Alexander and Litke, Alan M and Chichilnisky, E J and
               Simoncelli, Eero P",
  abstract  = "Statistical dependencies in the responses of sensory neurons
               govern both the amount of stimulus information conveyed and the
               means by which downstream neurons can extract it. Although a
               variety of measurements indicate the existence of such
               dependencies1, 2, 3, their origin and importance for neural
               coding are poorly understood. Here we analyse the functional
               significance of correlated firing in a complete population of
               macaque parasol retinal ganglion cells using a model of
               multi-neuron spike responses4, 5. The model, with parameters fit
               directly to physiological data, simultaneously captures both the
               stimulus dependence and detailed spatio-temporal correlations in
               population responses, and provides two insights into the
               structure of the neural code. First, neural encoding at the
               population level is less noisy than one would expect from the
               variability of individual neurons: spike times are more precise,
               and can be predicted more accurately when the spiking of
               neighbouring neurons is taken into account. Second, correlations
               provide additional sensory information: optimal, model-based
               decoding that exploits the response correlation structure
               extracts 20\% more information about the visual scene than
               decoding under the assumption of independence, and preserves
               40\% more visual information than optimal linear decoding6. This
               model-based approach reveals the role of correlated activity in
               the retinal coding of visual stimuli, and provides a general
               framework for understanding the importance of correlated
               activity in populations of neurons.",
  journal   = "Nature",
  publisher = "Macmillan Publishers Limited. All rights reserved",
  volume    =  454,
  number    =  7207,
  pages     = "995--999",
  month     =  aug,
  year      =  2008,
  keywords  = "glm, point-process-model, spike-train, visual",
  issn      = "0028-0836",
  pmid      = "18650810",
  doi       = "10.1038/nature07140"
}

@InProceedings{Arribas2020a,
  author    = {Diego M. Arribas and Yuan Zhao and Il Memming Park},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  title     = {Rescuing neural spike train models from bad {MLE}},
  abstract      = "The standard approach to fitting an autoregressive spike
                   train model is to maximize the likelihood for one-step
                   prediction. This maximum likelihood estimation (MLE) often
                   leads to models that perform poorly when generating samples
                   recursively for more than one time step. Moreover, the
                   generated spike trains can fail to capture important
                   features of the data and even show diverging firing rates.
                   To alleviate this, we propose to directly minimize the
                   divergence between neural recorded and model generated spike
                   trains using spike train kernels. We develop a method that
                   stochastically optimizes the maximum mean discrepancy
                   induced by the kernel. Experiments performed on both real
                   and synthetic neural data validate the proposed approach,
                   showing that it leads to well-behaving models. Using
                   different combinations of spike train kernels, we show that
                   we can control the trade-off between different features
                   which is critical for dealing with model-mismatch.",
  month         =  oct,
  year          =  2020,
  archivePrefix = "arXiv",
  eprint        = "2010.12362",
  primaryClass  = "stat.ML",
  arxivid       = "2010.12362",
  code		= {https://github.com/catniplab/mmd-glm},
}

@Article{Park2014d,
  author               = {Park, Il Memming and Meister, Miriam L. R. and Huk, Alexander C. and Pillow, Jonathan W.},
  title                = {Encoding and decoding in parietal cortex during sensorimotor decision-making},
  journal              = {Nature Neuroscience},
  year                 = {2014},
  volume               = {17},
  number               = {10},
  pages                = {1395--1403},
  month                = oct,
  issn                 = {1097-6256},
  citeulike-article-id = {13342234},
  citeulike-linkout-0  = {http://dx.doi.org/10.1038/nn.3800},
  doi                  = {10.1038/nn.3800},
  pdf       = {Park2014d_typofixed.pdf},
  keywords             = {computational-neuroscience, decision-making, glm, lip, monkey, neural-code, neural-decoding},
  posted-at            = {2014-08-31 22:37:11},
}

@Unpublished{Dowling2020a,
  author        = {Dowling, Matthew and Zhao, Yuan and Park, Il Memming},
  title         = {Non-parametric generalized linear model},
  month         = sep,
  year          = {2020},
  abstract      = {A fundamental problem in statistical neuroscience is to
                   model how neurons encode information by analyzing
                   electrophysiological recordings. A popular and widely-used
                   approach is to fit the spike trains with an autoregressive
                   point process model. These models are characterized by a set
                   of convolutional temporal filters, whose subsequent analysis
                   can help reveal how neurons encode stimuli, interact with
                   each other, and process information. In practice a
                   sufficiently rich but small ensemble of temporal basis
                   functions needs to be chosen to parameterize the filters.
                   However, obtaining a satisfactory fit often requires
                   burdensome model selection and fine tuning the form of the
                   basis functions and their temporal span. In this paper we
                   propose a nonparametric approach for jointly inferring the
                   filters and hyperparameters using the Gaussian process
                   framework. Our method is computationally efficient taking
                   advantage of the sparse variational approximation while
                   being flexible and rich enough to characterize arbitrary
                   filters in continuous time lag. Moreover, our method
                   automatically learns the temporal span of the filter. For
                   the particular application in neuroscience, we designed
                   priors for stimulus and history filters useful for the spike
                   trains. We compare and validate our method on simulated and
                   real neural spike train data.},
  archiveprefix = {arXiv},
  arxivid       = {2009.01362},
  eprint        = {2009.01362},
  primaryclass  = {stat.ML},
}

@BOOK{Dayan2001,
  title     = "Theoretical Neuroscience: Computational and Mathematical
               Modeling of Neural Systems",
  author    = "Dayan, Peter and Abbott, L F",
  publisher = "MIT Press",
  year      =  2001,
  address   = "Cambridge, MA, USA"
}

@ARTICLE{Stokes2017,
  title    = "A study of problems encountered in Granger causality analysis
              from a neuroscience perspective",
  author   = "Stokes, Patrick A and Purdon, Patrick L",
  abstract = "Granger causality methods were developed to analyze the flow of
              information between time series. These methods have become more
              widely applied in neuroscience. Frequency-domain causality
              measures, such as those of Geweke, as well as multivariate
              methods, have particular appeal in neuroscience due to the
              prevalence of oscillatory phenomena and highly multivariate
              experimental recordings. Despite its widespread application in
              many fields, there are ongoing concerns regarding the
              applicability of Granger causality methods in neuroscience. When
              are these methods appropriate? How reliably do they recover the
              system structure underlying the observed data? What do
              frequency-domain causality measures tell us about the functional
              properties of oscillatory neural systems? In this paper, we
              analyze fundamental properties of Granger-Geweke (GG) causality,
              both computational and conceptual. Specifically, we show that (i)
              GG causality estimates can be either severely biased or of high
              variance, both leading to spurious results; (ii) even if
              estimated correctly, GG causality estimates alone are not
              interpretable without examining the component behaviors of the
              system model; and (iii) GG causality ignores critical components
              of a system's dynamics. Based on this analysis, we find that the
              notion of causality quantified is incompatible with the
              objectives of many neuroscience investigations, leading to highly
              counterintuitive and potentially misleading results. Through the
              analysis of these problems, we provide important conceptual
              clarification of GG causality, with implications for other
              related causality approaches and for the role of causality
              analyses in neuroscience as a whole.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  114,
  number   =  34,
  pages    = "E7063--E7072",
  month    =  aug,
  year     =  2017,
  keywords = "Granger causality; connectivity; neural oscillations; system
              identification; time series analysis",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "28778996",
  doi      = "10.1073/pnas.1704663114",
  pmc      = "PMC5576801"
}

